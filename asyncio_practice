import aiohttp
import asyncio
import json
import time
import os
from packageurl import PackageURL
from bs4 import BeautifulSoup




async def fetch(session, url):
    async with session.get(url) as response:
        return await response.text()




async def fetch_all(session, urls):
    results = await asyncio.gather(
        *[fetch(session, url) for url in urls], return_exceptions=True
    )
    return results




async def get_package_info(session, package_name):
    url = f"https://pypi.org/pypi/{package_name}/json"
    async with session.get(url) as response:
        if response.status != 200:
            print(
                f"Failed to get info for package {package_name}: HTTP {response.status}"
            )
            return None


        data = await response.json()


        if "info" not in data:
            print(
                f"Failed to get info for package {package_name}: 'info' key not found in response"
            )
            return None

        purl = PackageURL(type='pypi', name=package_name).to_string()
        info = data["info"]
        project_urls = info.get("project_urls")
        source_repository = (
            project_urls.get("Homepage") if project_urls is not None else None
        )
        return {
            "name": info.get("name"),
            "version": info.get("version"),
            "source_repository": source_repository,
            "author": info.get("author"),
            "author_email": info.get("author_email"),
            "license": info.get("license"),
            "purl": purl,
        }




async def main():
    output_dir = "C:\\Users\\Sameer Bhagavatula\\Documents\\VS Code\\Securin Intership\\ASYNCIO PRACTICE FILES\\"
    url = "https://pypi.org/simple/"
    failed_packages = []
    async with aiohttp.ClientSession() as session:
        html = await fetch(session, url)
        soup = BeautifulSoup(html, "html.parser")
        package_links = [link.get("href") for link in soup.find_all("a")]
        package_names = [link.split("/")[-2] for link in package_links]


        package_infos = await asyncio.gather(
            *[get_package_info(session, package_name) for package_name in package_names]
        )


        for package_name, package_info in zip(package_names, package_infos):
            if package_info is not None:
                with open(f"{package_info['name']}.json", "w") as f:
                    json.dump(package_info, f)
            else:
                failed_packages.append(package_name)


        with open("failed_packages.json", "w") as f:
            json.dump(failed_packages, f)




if __name__ == "__main__":
    start_time = time.time()
    asyncio.run(main())
    end_time = time.time()
    print(f"Runtime: {end_time - start_time} seconds")
